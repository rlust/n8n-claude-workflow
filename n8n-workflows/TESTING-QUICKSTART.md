# Testing Quick Start Guide

Fast reference for running automated tests on n8n Claude workflows.

## âš¡ Quick Commands

```bash
# Install dependencies (first time only)
make install
# OR
pip install -r tests/requirements.txt

# Run all tests
make test

# Run fast tests only (skip slow agent tests)
make test-fast

# Run with coverage report
make test-coverage

# Generate HTML test report
make test-html
```

## ğŸ“Š What Gets Tested

âœ… **Code Analyzer** - Code analysis workflow
âœ… **Document Summarizer** - Document summarization
âœ… **Agent Workflows** - Autonomous agent tasks
âœ… **Performance** - Response times and concurrency
âœ… **Error Handling** - Invalid inputs and edge cases

## ğŸ¯ Common Test Scenarios

### Test Specific Workflow

```bash
# Test only code analyzer
pytest tests/test_workflows.py::TestCodeAnalyzer -v

# Test only document summarizer
pytest tests/test_workflows.py::TestDocumentSummarizer -v

# Test only agent workflows
pytest tests/test_workflows.py::TestAgentCodebaseAnalyzer -v
```

### Test by Category

```bash
# Skip slow tests (good for quick checks)
pytest tests/ -m "not slow" -v

# Run only performance tests
pytest tests/ -m "performance" -v

# Run only agent tests
pytest tests/ -m "agent" -v
```

### Debugging

```bash
# Stop at first failure
pytest tests/ -x -v

# Show print statements
pytest tests/ -s -v

# Full debug mode
make test-debug
```

## âœ… Validation Features

Each test automatically validates:
- âœ“ HTTP status codes
- âœ“ Response structure (required fields)
- âœ“ Success/failure status
- âœ“ Metadata completeness
- âœ“ Response content quality
- âœ“ Performance metrics

## ğŸ“ˆ Test Results

After running tests:

```bash
# View coverage report
open htmlcov/index.html

# View HTML test report
open test-results/report.html
```

## ğŸ”§ Configuration

Set environment variables if needed:

```bash
# Custom n8n URL
export N8N_BASE_URL="http://your-n8n-instance:5678"

# Custom timeout
export TEST_TIMEOUT=60

# Then run tests
make test
```

## ğŸš€ CI/CD

Tests run automatically on:
- Push to main/develop
- Pull requests
- Daily at 2 AM UTC
- Manual trigger in GitHub Actions

## ğŸ“ Test Structure

```
âœ“ 12+ test cases covering:
  â”œâ”€ Basic functionality
  â”œâ”€ Error handling
  â”œâ”€ Multiple languages/formats
  â”œâ”€ Input validation
  â”œâ”€ Performance SLA
  â””â”€ Concurrent requests
```

## ğŸ“ Examples

### Example Test Output

```
tests/test_workflows.py::TestCodeAnalyzer::test_basic_code_analysis PASSED [8%]
âœ“ Test completed in 1245.67ms

tests/test_workflows.py::TestCodeAnalyzer::test_code_analysis_with_issues PASSED [16%]
tests/test_workflows.py::TestDocumentSummarizer::test_basic_summarization PASSED [25%]
âœ“ Summarized in 1567.89ms
```

### Example Coverage Report

```
Name                    Stmts   Miss  Cover
-------------------------------------------
test_workflows.py        245     12    95%
conftest.py               28      2    93%
-------------------------------------------
TOTAL                    273     14    95%
```

## ğŸ†˜ Troubleshooting

### n8n not responding?
```bash
curl http://100.82.85.95:5678/healthz
```

### Tests timing out?
```bash
export TEST_TIMEOUT=60
make test
```

### Module not found?
```bash
make install
```

## ğŸ“š Full Documentation

For detailed information, see:
- `tests/README.md` - Complete testing guide
- `pytest.ini` - Test configuration
- `.github/workflows/test-workflows.yml` - CI/CD setup

---

**Need help?** Run `make help` for all available commands.
